import os
import json
import faiss
import numpy as np
from query.optimized_theme_matcher import ThemeMatcher
from query.reranker import SimpleReranker, LLMReranker
from query.enhanced_retriever import EnhancedRetriever
from query.query_rewriter import QueryRewriter, is_query_rewrite_enabled
from llm.llm import LLMClient
from llm.answer_selector import AnswerSelector
from graph.graph_utils import extract_entity_names, match_entities_in_query, extract_subgraph, summarize_subgraph
from query.query_classifier import classify_query_lightweight
from utils.io import load_chunks, load_vector_index, load_graph

def direct_vector_search(query: str, index, id_map: dict, chunks: list, config: dict, top_k: int = 5) -> list:
    """
    ç›´æ¥ä½¿ç”¨Faisså‘é‡ç´¢å¼•è¿›è¡Œç²¾ç¡®æŸ¥è¯¢ï¼Œè·³è¿‡ä¸»é¢˜æ‘˜è¦
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        index: Faissç´¢å¼•
        id_map: IDæ˜ å°„å­—å…¸
        chunks: æ–‡æ¡£å—åˆ—è¡¨
        config: é…ç½®å­—å…¸
        top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡
        
    Returns:
        æ£€ç´¢åˆ°çš„å€™é€‰ç»“æœåˆ—è¡¨ï¼ˆåŒ…å«textå’Œsimilarityå­—æ®µï¼‰
    """
    try:
        # ç»Ÿä¸€ä½¿ç”¨LLMClientè¿›è¡ŒåµŒå…¥å‘é‡ç”Ÿæˆ
        llm_client = LLMClient(config)
        
        # ç¼–ç æŸ¥è¯¢ï¼ˆå¯ç”¨æ–‡æœ¬é¢„å¤„ç†å’Œç»´åº¦éªŒè¯ï¼‰
        query_embeddings = llm_client.embed([query], normalize_text=True, validate_dim=True)
        if not query_embeddings:
            print(f"æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥: {query}")
            return []
            
        query_emb = np.array([query_embeddings[0]]).astype('float32')
        
        # æ£€æŸ¥å‘é‡æœ‰æ•ˆæ€§
        if query_emb.shape[1] == 0:
            print(f"æŸ¥è¯¢å‘é‡ä¸ºç©º: {query}")
            return []
            
        # æ£€æŸ¥æŸ¥è¯¢å‘é‡å¹…åº¦ï¼ˆå¼‚å¸¸æ£€æµ‹ï¼‰
        vector_magnitude = np.linalg.norm(query_emb)
        if vector_magnitude < 1e-6:
            print(f"âš ï¸ æŸ¥è¯¢å‘é‡å¹…åº¦è¿‡å°: {vector_magnitude}, å¯èƒ½å­˜åœ¨å¼‚å¸¸")
            return []
        
        # å½’ä¸€åŒ–æŸ¥è¯¢å‘é‡ä»¥ç¡®ä¿è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        import faiss
        faiss.normalize_L2(query_emb)
        
        # æ£€æŸ¥å½’ä¸€åŒ–åçš„å‘é‡
        if np.any(np.isnan(query_emb)) or np.any(np.isinf(query_emb)):
            print(f"æŸ¥è¯¢å‘é‡åŒ…å«æ— æ•ˆå€¼: {query}")
            return []
        
        # æœç´¢æœ€ç›¸ä¼¼çš„å‘é‡
        scores, indices = index.search(query_emb, top_k)
        
        candidates = []
        print("\n[ç›´æ¥å‘é‡æ£€ç´¢è¯¦æƒ…]")
        print("-" * 50)
        
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx == -1:  # Faissè¿”å›-1è¡¨ç¤ºæ— æ•ˆç»“æœ
                continue
                
            # ä»IDæ˜ å°„ä¸­è·å–åŸå§‹chunk ID
            chunk_id = id_map.get(str(idx))
            if chunk_id is None:
                continue
                
            # æŸ¥æ‰¾å¯¹åº”çš„æ–‡æ¡£å—
            chunk_text = next((c['text'] for c in chunks if c['id'] == chunk_id), None)
            if chunk_text:
                candidate = {
                    'text': chunk_text,
                    'similarity': float(score),
                    'id': chunk_id,
                    'source': 'direct_vector'
                }
                candidates.append(candidate)
                
                print(f"æ–‡æ¡£å— #{i+1}:")
                print(f"  ID: {chunk_id}")
                print(f"  ç›¸ä¼¼åº¦: {score:.4f}")
                print(f"  å†…å®¹: {chunk_text[:100]}..." if len(chunk_text) > 100 else f"  å†…å®¹: {chunk_text}")
                print("-" * 50)
        
        return candidates
        
    except Exception as e:
        print(f"âŒ ç›´æ¥å‘é‡æœç´¢å¤±è´¥: {e}")
        return []

def handle_query(query: str, config: dict, work_dir: str, mode: str = "auto", precise: bool = False, use_reranker: str = "simple", use_enhanced_retrieval: bool = True) -> dict:
    """
    å¤„ç†å•ä¸ªæŸ¥è¯¢
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        config: é…ç½®å­—å…¸
        work_dir: å·¥ä½œç›®å½•
        mode: æŸ¥è¯¢æ¨¡å¼
        precise: æ˜¯å¦ç²¾ç¡®æŸ¥è¯¢
        use_reranker: é‡æ’åºå™¨ç±»å‹
        use_enhanced_retrieval: æ˜¯å¦ä½¿ç”¨å¢å¼ºæ£€ç´¢
        
    Returns:
        åŒ…å«ç­”æ¡ˆã€æ¥æºå’Œå¤„ç†æ—¶é—´çš„å­—å…¸
    """
    import time
    start_time = time.time()
    
    # æŸ¥è¯¢æ”¹å†™å¤„ç†
    original_query = query
    rewrite_result = None
    
    if is_query_rewrite_enabled(config):
        try:
            rewriter = QueryRewriter(config)
            rewrite_result = rewriter.rewrite_query(query)
            
            # æ ¹æ®è¯„ä¼°ç»“æœå†³å®šæ˜¯å¦ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢
            if (rewrite_result.get("evaluation", {}).get("recommendation") == "accept" or 
                not rewrite_result.get("evaluation")):
                query = rewrite_result["rewritten_query"]
                print(f"[æŸ¥è¯¢æ”¹å†™] åŸå§‹æŸ¥è¯¢: {original_query}")
                print(f"[æŸ¥è¯¢æ”¹å†™] æ”¹å†™æŸ¥è¯¢: {query}")
                print(f"[æŸ¥è¯¢æ”¹å†™] ç­–ç•¥: {rewrite_result['strategy']}")
            else:
                print(f"[æŸ¥è¯¢æ”¹å†™] æ”¹å†™è¢«æ‹’ç»ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")
                query = original_query
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢æ”¹å†™å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢: {e}")
            query = original_query
    
    llm = LLMClient(config)
    chunks = load_chunks(work_dir)
    index, id_map = load_vector_index(work_dir)
    
    # åŠ è½½å›¾è°±
    graph_path = os.path.join(work_dir, "graph.json")
    graph = load_graph(work_dir) if os.path.exists(graph_path) else None
    entity_names = extract_entity_names(graph) if graph else set()
    
    # å¦‚æœæ˜¯autoæ¨¡å¼ï¼Œè¿›è¡Œè‡ªåŠ¨åˆ†ç±»
    if mode == "auto":
        original_mode, original_precise = classify_query_lightweight(query, config)
        from query.query_enhancer import enhance_query_classification
        mode, precise = enhance_query_classification(query, original_mode, original_precise)
    
    # å¤„ç†noragæ¨¡å¼
    if mode == "norag":
        response = llm.generate(f"è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š\n{query}")
        return {
            'answer': response.strip(),
            'sources': [],
            'processing_time': time.time() - start_time,
            'enhanced_retrieval': False
        }
    
    # æ£€ç´¢å€™é€‰æ–‡æ¡£
    candidates = []
    
    if use_enhanced_retrieval:
        # ä½¿ç”¨å¢å¼ºæ£€ç´¢å™¨
        retriever = EnhancedRetriever(config, work_dir)
        candidates = retriever.retrieve(query, top_k=10)
    else:
        # ä¼ ç»Ÿæ£€ç´¢æ–¹æ³•
        if precise and index is not None:
            candidates = direct_vector_search(query, index, id_map, chunks, config, top_k=10)
        else:
            matcher = ThemeMatcher(chunks, config)
            matches = matcher.match(query, top_k=10, min_score=0.3)
            
            for match in matches:
                topic_id = match["node_id"]
                similarity = match.get("similarity", 0.0)
                topic_title = match.get("title", "æ— æ ‡é¢˜")
                match_text = next((c['text'] for c in chunks if c['id'] == topic_id), None)
                
                if match_text:
                    candidate = {
                        'text': match_text,
                        'similarity': similarity,
                        'id': topic_id,
                        'title': topic_title,
                        'source': 'theme_matcher'
                    }
                    candidates.append(candidate)
    
    # åº”ç”¨é‡æ’åº
    if use_reranker != "none" and candidates:
        rerank_config = config.get("rerank", {})
        if use_reranker == "llm":
            reranker = LLMReranker(llm, rerank_config)
        else:
            reranker = SimpleReranker(rerank_config)
        
        candidates = reranker.rerank(query, candidates, top_k=5)
    else:
        candidates = candidates[:5]
    
    # æå–æ–‡æœ¬ç”¨äºç”Ÿæˆå›ç­”
    retrieved = [c['text'] for c in candidates]
    context = "\n".join(retrieved) if retrieved else "ï¼ˆæœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æœ¬å†…å®¹ï¼‰"
    
    # å›¾è°±æ‘˜è¦
    graph_summary = ""
    if graph:
        try:
            matched_entities = match_entities_in_query(query, entity_names)
            subgraph = extract_subgraph(graph, matched_entities)
            graph_summary = summarize_subgraph(subgraph)
        except Exception:
            pass
    
    # ç”Ÿæˆå›ç­” - ä½¿ç”¨ç­”æ¡ˆé€‰æ‹©å™¨
    answer_selector_config = config.get('answer_selector', {})
    answer_selector = AnswerSelector(llm, answer_selector_config)
    
    # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
    full_context = context
    if graph_summary:
        full_context += f"\n\nå›¾è°±æ‘˜è¦ï¼š\n{graph_summary}"
    
    # æå–å®ä½“ç”¨äºå¤æ‚åº¦åˆ¤æ–­
    entities = []
    if graph:
        try:
            entities = match_entities_in_query(query, entity_names)
        except Exception:
            pass
    
    # ä½¿ç”¨ç­”æ¡ˆé€‰æ‹©å™¨ç”Ÿæˆæœ€ä½³ç­”æ¡ˆ
    answer, selection_metadata = answer_selector.select_best_answer(
        query=query, 
        context=full_context, 
        entities=entities
    )
    
    return {
        'answer': answer.strip(),
        'sources': candidates,
        'processing_time': time.time() - start_time,
        'enhanced_retrieval': use_enhanced_retrieval,
        'answer_selection': selection_metadata,
        'query_rewrite': {
            'enabled': is_query_rewrite_enabled(config),
            'original_query': original_query,
            'final_query': query,
            'rewrite_result': rewrite_result
        }
    }

def run_query_loop(config: dict, work_dir: str, logger=None):
    """
    è¿è¡ŒæŸ¥è¯¢å¾ªç¯
    
    Args:
        config: é…ç½®å­—å…¸
        work_dir: å·¥ä½œç›®å½•
        logger: æ—¥å¿—å¯¹è±¡
    """
    if logger:
        logger.info("å¼€å§‹æŸ¥è¯¢å¾ªç¯")
    
    print("\nğŸ” RAGæŸ¥è¯¢ç³»ç»Ÿå·²å¯åŠ¨")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("è¾“å…¥ 'mode <æ¨¡å¼>' åˆ‡æ¢æŸ¥è¯¢æ¨¡å¼ (norag, hybrid_precise, hybrid_imprecise, auto)")
    print("è¾“å…¥ 'reranker <ç±»å‹>' åˆ‡æ¢é‡æ’åºå™¨ (simple, llm, none)")
    print("è¾“å…¥ 'enhanced <on/off>' åˆ‡æ¢å¢å¼ºæ£€ç´¢")
    print("-" * 50)
    
    current_mode = "auto"
    current_reranker = "simple"
    use_enhanced = True
    
    while True:
        try:
            user_input = input("\nè¯·è¾“å…¥æŸ¥è¯¢: ").strip()
            
            if user_input.lower() in ['quit', 'exit']:
                print("å†è§ï¼")
                break
            
            if user_input.startswith('mode '):
                new_mode = user_input[5:].strip()
                if new_mode in ['norag', 'hybrid_precise', 'hybrid_imprecise', 'auto']:
                    current_mode = new_mode
                    print(f"âœ… æŸ¥è¯¢æ¨¡å¼å·²åˆ‡æ¢ä¸º: {current_mode}")
                else:
                    print("âŒ æ— æ•ˆæ¨¡å¼ï¼Œå¯é€‰: norag, hybrid_precise, hybrid_imprecise, auto")
                continue
            
            if user_input.startswith('reranker '):
                new_reranker = user_input[9:].strip()
                if new_reranker in ['simple', 'llm', 'none']:
                    current_reranker = new_reranker
                    print(f"âœ… é‡æ’åºå™¨å·²åˆ‡æ¢ä¸º: {current_reranker}")
                else:
                    print("âŒ æ— æ•ˆé‡æ’åºå™¨ï¼Œå¯é€‰: simple, llm, none")
                continue
                
            if user_input.startswith('enhanced '):
                enhanced_setting = user_input[9:].strip().lower()
                if enhanced_setting in ['on', 'true', '1']:
                    use_enhanced = True
                    print("âœ… å¢å¼ºæ£€ç´¢å·²å¯ç”¨")
                elif enhanced_setting in ['off', 'false', '0']:
                    use_enhanced = False
                    print("âœ… å¢å¼ºæ£€ç´¢å·²ç¦ç”¨")
                else:
                    print("âŒ æ— æ•ˆè®¾ç½®ï¼Œè¯·ä½¿ç”¨ on/off")
                continue
            
            if not user_input:
                continue
            
            print(f"\nğŸ” æŸ¥è¯¢æ¨¡å¼: {current_mode}, é‡æ’åºå™¨: {current_reranker}, å¢å¼ºæ£€ç´¢: {'å¼€å¯' if use_enhanced else 'å…³é—­'}")
            
            # å¤„ç†æŸ¥è¯¢
            result = handle_query(
                query=user_input,
                config=config,
                work_dir=work_dir,
                mode=current_mode,
                use_reranker=current_reranker,
                use_enhanced_retrieval=use_enhanced
            )
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“ å›ç­”:")
            print(result['answer'])
            
            # æ˜¾ç¤ºç­”æ¡ˆé€‰æ‹©ä¿¡æ¯
            if 'answer_selection' in result:
                selection_info = result['answer_selection']
                method = selection_info.get('method', 'unknown')
                candidates_count = selection_info.get('candidates_count', 0)
                
                if method == 'multi' and candidates_count > 1:
                    best_score = selection_info.get('best_score', 0)
                    print(f"\nğŸ¯ ç­”æ¡ˆé€‰æ‹©: å¤šå€™é€‰æ¨¡å¼ ({candidates_count}ä¸ªå€™é€‰ç­”æ¡ˆ, æœ€ä½³è¯„åˆ†: {best_score:.1f})")
                    if 'best_reasoning' in selection_info:
                        print(f"   é€‰æ‹©ç†ç”±: {selection_info['best_reasoning']}")
                elif method == 'multi':
                    print(f"\nğŸ¯ ç­”æ¡ˆé€‰æ‹©: å¤šå€™é€‰æ¨¡å¼ ({candidates_count}ä¸ªå€™é€‰ç­”æ¡ˆ)")
                else:
                    print(f"\nğŸ¯ ç­”æ¡ˆé€‰æ‹©: å•ä¸€ç­”æ¡ˆæ¨¡å¼")
            
            if result['sources']:
                print(f"\nğŸ“š å‚è€ƒæ¥æº ({len(result['sources'])}ä¸ª):")
                for i, source in enumerate(result['sources'], 1):
                    similarity = source.get('similarity', 0)
                    retrieval_info = ""
                    if 'retrieval_types' in source:
                        retrieval_info = f" [{','.join(source['retrieval_types'])}]"
                    elif 'retrieval_type' in source:
                        retrieval_info = f" [{source['retrieval_type']}]"
                    print(f"{i}. [ç›¸ä¼¼åº¦: {similarity:.3f}]{retrieval_info} {source['text']}")
            
            processing_time = result['processing_time']
            enhanced_status = "(å¢å¼ºæ£€ç´¢)" if result.get('enhanced_retrieval') else "(ä¼ ç»Ÿæ£€ç´¢)"
            print(f"\nâ±ï¸ å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’ {enhanced_status}")
            
        except KeyboardInterrupt:
            print("\n\nå†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
